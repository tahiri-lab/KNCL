{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "702438b5",
   "metadata": {},
   "source": [
    "# Runtime and memory evaluation of the overlapping phylogenetic tree dataset pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30f930e",
   "metadata": {},
   "source": [
    "This script evaluates the **runtime performance** and **peak memory usage** of the proposed data pipeline.\n",
    "\n",
    "The pipeline is designed to generate biologically meaningful datasets of phylogenetic trees with controlled taxon overlap, supporting applications such as supertree construction, tree comparison, and phylogenetic clustering.\n",
    "\n",
    "### Scope of evaluation\n",
    "\n",
    "This runtime analysis covers all major stages of the pipeline, including:\n",
    "\n",
    "1. **Loading species lists** from a main CSV file (`all_species_lists.csv`)\n",
    "2. **Random selection of species** within families to form the dataset\n",
    "3. **Computation of overlapping subsets** using predefined taxon overlap percentages\n",
    "4. **Unzipping pre-downloaded VertLife tree files**\n",
    "5. **Conversion raw trees to Newick format** and dataset combining\n",
    "\n",
    "> The step of requesting tree data from the VertLife webserver is excluded from this evaluation, as it introduces variability from external network latency and server processing times. Pre-downloaded ZIP archives of tree files are used instead.\n",
    "\n",
    "### Datasets evaluated\n",
    "\n",
    "The script evaluates four datasets:\n",
    "\n",
    "| Dataset    | Unique Species | Trees per Subset | Total Trees |\n",
    "| ---------- | -------------- | ---------------- | ----------- |\n",
    "| Amphibians | 120            | 55               | 550         |\n",
    "| Birds      | 135            | 60               | 600         |\n",
    "| Mammals    | 105            | 50               | 500         |\n",
    "| Sharks     | 95             | 45               | 450         |\n",
    "\n",
    "### Output\n",
    "\n",
    "For each dataset, the script records:\n",
    "\n",
    "* **Total runtime** (in seconds)\n",
    "* **Peak memory usage** (in MB)\n",
    "* **System specifications** for reproducibility\n",
    "\n",
    "The results are summarized in a final performance table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5095ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting biopython\n",
      "  Downloading biopython-1.85-cp39-cp39-win_amd64.whl (2.8 MB)\n",
      "Collecting memory_profiler\n",
      "  Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\kosa2601\\anaconda3\\lib\\site-packages (from biopython) (1.20.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\kosa2601\\anaconda3\\lib\\site-packages (from memory_profiler) (5.8.0)\n",
      "Installing collected packages: memory-profiler, biopython\n",
      "Successfully installed biopython-1.85 memory-profiler-0.61.0\n"
     ]
    }
   ],
   "source": [
    "!pip install biopython memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06ffeca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== System Info ===\n",
      "Platform: Windows 10\n",
      "Processor: Intel64 Family 6 Model 140 Stepping 1, GenuineIntel\n",
      "Architecture: AMD64\n",
      "CPU cores: 4\n",
      "Logical processors: 8\n",
      "Total RAM: 31.69 GB\n",
      "\n",
      "=== Full Pipeline Runtime Evaluation ===\n",
      "\n",
      "Processing Amphibians...\n",
      "\n",
      "Processing Birds...\n",
      "\n",
      "Processing Mammals...\n",
      "\n",
      "Processing Sharks...\n",
      "\n",
      "=== Summary Table ===\n",
      "   Dataset  Unique Species  Trees per Subset  Total Trees  Runtime (sec)  Peak Memory (MB)\n",
      "Amphibians             120                55          550            3.8             120.2\n",
      "     Birds             135                60          600            4.7             124.7\n",
      "   Mammals             105                50          500            2.9             118.9\n",
      "    Sharks              95                45          450            2.0             114.8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import random\n",
    "import psutil\n",
    "import platform\n",
    "import pandas as pd\n",
    "from Bio import Phylo\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "# === SYSTEM INFO ===\n",
    "def print_system_info():\n",
    "    print(\"=== System Info ===\")\n",
    "    print(f\"Platform: {platform.system()} {platform.release()}\")\n",
    "    print(f\"Processor: {platform.processor()}\")\n",
    "    print(f\"Architecture: {platform.machine()}\")\n",
    "    print(f\"CPU cores: {psutil.cpu_count(logical=False)}\")\n",
    "    print(f\"Logical processors: {psutil.cpu_count(logical=True)}\")\n",
    "    print(f\"Total RAM: {round(psutil.virtual_memory().total / (1024 ** 3), 2)} GB\")\n",
    "\n",
    "# === GROUPING FUNCTION ===\n",
    "def select_one_per_subgroup(species_list):\n",
    "    subgroups = {}\n",
    "    for species in species_list:\n",
    "        subgroup = species.split()[0]\n",
    "        if subgroup not in subgroups:\n",
    "            subgroups[subgroup] = species\n",
    "    return list(subgroups.values())\n",
    "\n",
    "# === OVERLAPPING SUBSET GENERATION ===\n",
    "def calculate_n_for_k(k, p_values=[0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1]):\n",
    "    n = k\n",
    "    previous_new_species = 0\n",
    "    for p in p_values:\n",
    "        common_species = (2 * k * p) / (1 + p)\n",
    "        rounded_common_species = round(common_species)\n",
    "        new_species = k - rounded_common_species\n",
    "        actual_new_species = new_species - previous_new_species\n",
    "        n += int(actual_new_species)\n",
    "        previous_new_species = new_species\n",
    "    return int(n)\n",
    "\n",
    "def find_k_from_n(n, max_k=1000, p_values=[0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1]):\n",
    "    for k in range(1, max_k+1):\n",
    "        if calculate_n_for_k(k, p_values) >= n:\n",
    "            return k\n",
    "    return None\n",
    "\n",
    "def generate_overlapping_subsets(species_list, n, group, p_values=[0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1]):\n",
    "    assert len(species_list) >= n, \"Not enough species!\"\n",
    "    selected = species_list[:n]\n",
    "    k = find_k_from_n(n, p_values=p_values)\n",
    "    if k is None:\n",
    "        raise ValueError(\"Could not find valid k for given n.\")\n",
    "\n",
    "    subsets = {f\"Subset {i}\": [] for i in range(1, 11)}\n",
    "    start_index = 0\n",
    "    subsets[\"Subset 1\"] = selected[start_index:start_index + k]\n",
    "    current_position = start_index + k\n",
    "\n",
    "    for i, p in enumerate(p_values, start=2):\n",
    "        common_species = round((2 * k * p) / (1 + p))\n",
    "        new_species = k - common_species\n",
    "        subset_start = start_index + int(new_species)\n",
    "        subset_end = subset_start + k\n",
    "        \n",
    "        subset_species = selected[subset_start:subset_end]\n",
    "        if len(subset_species) < k:\n",
    "            subset_species += selected[:k - len(subset_species)]\n",
    "        subsets[f\"Subset {i}\"] = subset_species\n",
    "        current_position = subset_start + k\n",
    "\n",
    "    max_len = len(selected)\n",
    "    for key in subsets:\n",
    "        subsets[key] += [None] * (max_len - len(subsets[key]))\n",
    "\n",
    "    df = pd.DataFrame(subsets)\n",
    "    df.to_csv(f\"{group}_overlapping_subsets.csv\", index=False)\n",
    "    return df\n",
    "\n",
    "# === TREE CONVERSION ===\n",
    "def unzip_all_in_folder(folder):\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith(\".zip\"):\n",
    "            zip_path = os.path.join(folder, file)\n",
    "            zip_base = os.path.splitext(file)[0]  # Use job_id as prefix\n",
    "            try:\n",
    "                with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                    for name in zip_ref.namelist():\n",
    "                        if name.endswith(\".nex\"):\n",
    "                            new_name = f\"{zip_base}.nex\"\n",
    "                            extracted_path = os.path.join(folder, new_name)\n",
    "                            with zip_ref.open(name) as src, open(extracted_path, 'wb') as dst:\n",
    "                                dst.write(src.read())\n",
    "            except zipfile.BadZipFile:\n",
    "                print(f\"Skipping bad zip: {zip_path}\")\n",
    "\n",
    "def convert_nexus_to_newick(nexus_file, t):\n",
    "    try:\n",
    "        trees = list(Phylo.parse(nexus_file, \"nexus\"))\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to parse {nexus_file}: {e}\")\n",
    "        return []\n",
    "\n",
    "    if len(trees) < t:\n",
    "        t = len(trees)\n",
    "    selected = random.sample(trees, t)\n",
    "    return [tree.format('newick').strip() for tree in selected if tree]\n",
    "\n",
    "# === FULL DATASET PROCESSING ===\n",
    "def process_dataset(group, folder, species_list, n, t):\n",
    "    p_values = [0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "\n",
    "    def full_pipeline():\n",
    "        # Select unique families (genus level)\n",
    "        unique_families = select_one_per_subgroup(species_list)\n",
    "        if len(unique_families) < n:\n",
    "            raise ValueError(f\"Not enough unique subgroups to select {n} species for {group}.\")\n",
    "        _ = generate_overlapping_subsets(unique_families, n, group, p_values)\n",
    "\n",
    "        # Unzip and process Nexus files\n",
    "        unzip_all_in_folder(folder)\n",
    "        all_newick = []\n",
    "        for file in os.listdir(folder):\n",
    "            if file.endswith(\".nex\"):\n",
    "                fpath = os.path.join(folder, file)\n",
    "                all_newick.extend(convert_nexus_to_newick(fpath, t))\n",
    "        with open(f\"overlapping_dataset_{group}.txt\", \"w\") as f:\n",
    "            for tree in all_newick:\n",
    "                f.write(tree + '\\n')\n",
    "\n",
    "    start = time.time()\n",
    "    peak_mem = memory_usage(full_pipeline, max_usage=True, interval=0.1)\n",
    "    runtime = time.time() - start\n",
    "    #return round(runtime / 60, 1), round(peak_mem, 1)\n",
    "    return round(runtime, 1), round(peak_mem, 1)\n",
    "\n",
    "# === DATASETS TO EVALUATE ===\n",
    "all_species_lists = pd.read_csv(\"all_species_lists.csv\")\n",
    "datasets = {\n",
    "    \"amphibians\": {\"folder\": \"amphibians_nexus\", \"t\": 55, \"n\": 120},\n",
    "    \"birds\": {\"folder\": \"birds_nexus\", \"t\": 60, \"n\": 135},\n",
    "    \"mammals\": {\"folder\": \"mammals_nexus\", \"t\": 50, \"n\": 105},\n",
    "    \"sharks\": {\"folder\": \"sharks_nexus\", \"t\": 45, \"n\": 95},\n",
    "}\n",
    "\n",
    "species_dict = {\n",
    "    \"amphibians\": all_species_lists['Amphibians'].dropna().tolist(),\n",
    "    \"birds\": all_species_lists['Birds'].dropna().tolist(),\n",
    "    \"mammals\": all_species_lists['Mammals'].dropna().tolist(),\n",
    "    \"sharks\": all_species_lists['Sharks'].dropna().tolist(),\n",
    "}\n",
    "\n",
    "# === RUN EVALUATION ===\n",
    "print_system_info()\n",
    "print(\"\\n=== Full Pipeline Runtime Evaluation ===\")\n",
    "results = []\n",
    "\n",
    "for group, cfg in datasets.items():\n",
    "    print(f\"\\nProcessing {group.capitalize()}...\")\n",
    "    species_list = species_dict[group]\n",
    "    runtime, mem = process_dataset(group, cfg[\"folder\"], species_list, cfg[\"n\"], cfg[\"t\"])\n",
    "    results.append({\n",
    "        \"Dataset\": group.capitalize(),\n",
    "        \"Unique Species\": cfg[\"n\"],\n",
    "        \"Trees per Subset\": cfg[\"t\"],\n",
    "        \"Total Trees\": cfg[\"t\"] * 10,\n",
    "        \"Runtime (sec)\": runtime,\n",
    "        \"Peak Memory (MB)\": mem\n",
    "    })\n",
    "\n",
    "# === DISPLAY SUMMARY TABLE ===\n",
    "df = pd.DataFrame(results)\n",
    "print(\"\\n=== Summary Table ===\")\n",
    "print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c48a6e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
